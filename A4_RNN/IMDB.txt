#using IMDb dataset
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Bidirectional
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt

# Parameters
vocab_size = 10000
maxlen = 200
embedding_dim = 32
batch_size = 64
epochs = 3

# Load IMDB dataset
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

# Models to compare
models = {
    "Simple RNN": Sequential([
        Embedding(vocab_size, embedding_dim, input_length=maxlen),
        SimpleRNN(32),
        Dense(1, activation='sigmoid')
    ]),

    "Bi-RNN": Sequential([
        Embedding(vocab_size, embedding_dim, input_length=maxlen),
        Bidirectional(SimpleRNN(32)),
        Dense(1, activation='sigmoid')
    ]),

    "LSTM": Sequential([
        Embedding(vocab_size, embedding_dim, input_length=maxlen),
        LSTM(32),
        Dense(1, activation='sigmoid')
    ]),

    "Bi-LSTM": Sequential([
        Embedding(vocab_size, embedding_dim, input_length=maxlen),
        Bidirectional(LSTM(32)),
        Dense(1, activation='sigmoid')
    ]),

    "GRU": Sequential([
        Embedding(vocab_size, embedding_dim, input_length=maxlen),
        GRU(32),
        Dense(1, activation='sigmoid')
    ])
}

# Train and evaluate each model
history_dict = {}
acc_results = {}

for name, model in models.items():
    print(f"\nTraining {name}...")
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,
                        validation_split=0.2, verbose=2)
    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)
    acc_results[name] = accuracy
    history_dict[name] = history

# Show final accuracy comparison
print("\nFinal Test Accuracy:")
for name, acc in acc_results.items():
    print(f"{name}: {acc:.4f}")

# Plot accuracy curves
plt.figure(figsize=(10, 6))
for name, history in history_dict.items():
    plt.plot(history.history['val_accuracy'], label=name)
plt.title("Validation Accuracy Comparison")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
