# q3
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

# 1. Load Dataset
(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()

# Explore dataset
print("Training data shape:", x_train.shape)
print("Testing data shape:", x_test.shape)
print("Training labels shape:", y_train.shape)
print("Unique classes:", np.unique(y_train))
print("Number of classes:", len(np.unique(y_train)))

# Normalize and reshape
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# 2. Display sample original images
plt.figure(figsize=(6, 6))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(x_train[i].reshape(28, 28), cmap="gray")
    plt.title(f"Label: {y_train[i]}")
    plt.axis("off")
plt.suptitle("Original MNIST Images")
plt.show()

# 3. Build CNN Model (with explicit Input)
inputs = tf.keras.Input(shape=(28, 28, 1))
x = layers.Conv2D(32, (3, 3), activation="relu")(inputs)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Conv2D(64, (3, 3), activation="relu")(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Conv2D(64, (3, 3), activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(64, activation="relu")(x)
outputs = layers.Dense(10, activation="softmax")(x)

model = models.Model(inputs=inputs, outputs=outputs)

# 4. Compile Model
model.compile(optimizer="adam",
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

# 5. Model Summary
model.summary()

# 6. Train Model
history = model.fit(x_train, y_train, epochs=5,
                    validation_data=(x_test, y_test),
                    batch_size=64)

# 7. Evaluate Model
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f"\nâœ… Test Accuracy: {test_acc*100:.2f}%")

# 8. Plot Training History
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history["accuracy"], label="Training Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.title("Model Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Model Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.show()

# 9. Show CNN Feature Maps (Intermediate Outputs)
# Pick one sample image
sample_img = x_train[0].reshape(1, 28, 28, 1)

# Extract outputs from each conv layer
layer_outputs = [layer.output for layer in model.layers if isinstance(layer, layers.Conv2D)]
activation_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)

# Get feature maps
feature_maps = activation_model.predict(sample_img)

# Plot feature maps for each conv layer
for layer_index, fmap in enumerate(feature_maps):
    num_filters = fmap.shape[-1]
    size = fmap.shape[1]
    display_grid = np.zeros((size, size * min(num_filters, 8)))  # Show max 8 filters per layer

    for i in range(min(num_filters, 8)):
        x = fmap[0, :, :, i]
        x -= x.mean()
        x /= (x.std() + 1e-5)
        x *= 64
        x += 128
        x = np.clip(x, 0, 255).astype("uint8")
        display_grid[:, i * size:(i + 1) * size] = x

    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))
    plt.title(f"Feature Maps from Conv Layer {layer_index+1}")
    plt.grid(False)
    plt.imshow(display_grid, aspect="auto", cmap="viridis")
    plt.show()






# ---- Show CNN Feature Maps for First 10 Images ----
# Create model to output intermediate conv layers
conv_layers = [layer.output for layer in model.layers if isinstance(layer, layers.Conv2D)]
activation_model = models.Model(inputs=model.input, outputs=conv_layers)

# Loop through first 10 test images
for img_index in range(10):
    sample_img = x_test[img_index].reshape(1, 28, 28, 1)  # single image
    label = y_test[img_index]

    # Get activations for this image
    feature_maps = activation_model.predict(sample_img)

    print(f"\nðŸ”Ž Original Image {img_index+1} (Label: {label})")
    plt.imshow(sample_img.reshape(28, 28), cmap="gray")
    plt.axis("off")
    plt.show()

    # Plot feature maps for each conv layer
    for layer_index, fmap in enumerate(feature_maps):
        num_filters = fmap.shape[-1]
        size = fmap.shape[1]
        display_grid = np.zeros((size, size * min(num_filters, 8)))  # max 8 filters

        for i in range(min(num_filters, 8)):
            x = fmap[0, :, :, i]
            x -= x.mean()
            x /= (x.std() + 1e-5)
            x *= 64
            x += 128
            x = np.clip(x, 0, 255).astype("uint8")
            display_grid[:, i * size:(i + 1) * size] = x

        scale = 1. / size
        plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))
        plt.title(f"Feature Maps - Conv Layer {layer_index+1} (Image {img_index+1})")
        plt.grid(False)
        plt.imshow(display_grid, aspect="auto", cmap="viridis")
        plt.show()
