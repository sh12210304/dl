#extra quest
import numpy as np
import matplotlib.pyplot as plt

def hard_tanh(x):
    return np.maximum(-1, np.minimum(1, x))
def leaky_relu(x, alpha=0.01):
    return np.maximum(alpha * x, x)

def elu(x, alpha=1.0):
    return np.where(x > 0, x, alpha * (np.exp(x) - 1))

x = np.linspace(-5, 5, 100)

plt.figure(figsize=(10, 8))

plt.plot(x, hard_tanh(x), label='Hard Tanh')
plt.plot(x, leaky_relu(x), label='Leaky ReLU')
plt.plot(x, elu(x), label='ELU')

plt.title('Activation Functions')
plt.xlabel('Input')
plt.ylabel('Output')
plt.legend()
plt.grid(True)
plt.show()